{'dataset_params': {'im_path': 'data/train/images'}, 'diffusion_params': {'num_timesteps': 1000, 'beta_start': 0.0001, 'beta_end': 0.02}, 'model_params': {'im_channels': 3, 'im_size': 32, 'down_channels': [32, 64, 128, 256], 'mid_channels': [256, 256, 256], 'down_sample': [True, True, False], 'time_emb_dim': 128, 'num_down_layers': 3, 'num_mid_layers': 3, 'num_up_layers': 3, 'num_heads': 4}, 'train_params': {'task_name': 'cifar10_improved_baseline', 'batch_size': 128, 'num_epochs': 200, 'num_samples': 1000, 'num_samples_progress': 10, 'num_grid_rows': 10, 'lr': 0.0001, 'ckpt_name': 'ddpm_ckpt.pth'}}
Epoch 1/200, Loss: 0.18283843176672832
Epoch 2/200, Loss: 0.06257187414085469
Epoch 3/200, Loss: 0.05203862202441906
Epoch 4/200, Loss: 0.04762151996936182
Epoch 5/200, Loss: 0.04424204656382656
Epoch 6/200, Loss: 0.04179392642129565
Epoch 7/200, Loss: 0.03999085960638188
Epoch 8/200, Loss: 0.03934891166551339
Epoch 9/200, Loss: 0.03758597490675462
Epoch 10/200, Loss: 0.0375016510410382
Epoch 11/200, Loss: 0.035888718355380364
Epoch 12/200, Loss: 0.03655399314944854
Epoch 13/200, Loss: 0.03551762707321845
Epoch 14/200, Loss: 0.0352667234504543
Epoch 15/200, Loss: 0.034605357438668875
Epoch 16/200, Loss: 0.03463195035677127
Epoch 17/200, Loss: 0.03473770946188046
Epoch 18/200, Loss: 0.03417978645838283
Epoch 19/200, Loss: 0.033802360286721796
Epoch 20/200, Loss: 0.0336323534769704
Epoch 21/200, Loss: 0.034101856672359855
Epoch 22/200, Loss: 0.03420141110163363
Epoch 23/200, Loss: 0.03384274946968726
Epoch 24/200, Loss: 0.03288811228007002
Epoch 25/200, Loss: 0.03312979477083744
Epoch 26/200, Loss: 0.033070018381604456
Epoch 27/200, Loss: 0.032892135779380494
Epoch 28/200, Loss: 0.033150705363591916
Epoch 29/200, Loss: 0.03292008742328038
Epoch 30/200, Loss: 0.0326114700454504
Epoch 31/200, Loss: 0.03283300344139109
Epoch 32/200, Loss: 0.03240666369362103
Epoch 33/200, Loss: 0.03251367724498214
Epoch 34/200, Loss: 0.03216733393328421
Epoch 35/200, Loss: 0.032204858234623816
Epoch 36/200, Loss: 0.031933463300051895
Epoch 37/200, Loss: 0.03262248396149377
Epoch 38/200, Loss: 0.031608328599568525
Epoch 39/200, Loss: 0.03223917899591386
Epoch 40/200, Loss: 0.032622080996556356
Epoch 41/200, Loss: 0.03221513847332171
Epoch 42/200, Loss: 0.031977225842949986
Epoch 43/200, Loss: 0.03132306898722563
Epoch 44/200, Loss: 0.03181249719313191
Epoch 45/200, Loss: 0.03219612732605861
Epoch 46/200, Loss: 0.03156309910213856
Epoch 47/200, Loss: 0.03159245080255029
Epoch 48/200, Loss: 0.031760475167151914
Epoch 49/200, Loss: 0.03140975388667315
Epoch 50/200, Loss: 0.03140833705206356
Epoch 51/200, Loss: 0.031366622742370266
Epoch 52/200, Loss: 0.03199269300531548
Epoch 53/200, Loss: 0.03164706588305933
Epoch 54/200, Loss: 0.031205455198541017
Epoch 55/200, Loss: 0.03142998487119327
Epoch 56/200, Loss: 0.03181133564571133
Epoch 57/200, Loss: 0.031687071480219015
Epoch 58/200, Loss: 0.03127651322452004
Epoch 59/200, Loss: 0.031335877226022504
[2025-12-06T04:05:53.002] error: *** JOB 405797 ON scholar-j000 CANCELLED AT 2025-12-06T04:05:53 DUE TO TIME LIMIT ***
